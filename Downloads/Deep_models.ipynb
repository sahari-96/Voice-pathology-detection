{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wJhWOZ4Zuu2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dropout, Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: LSTM-based model for training and classification\n",
        "model_1 = Sequential([\n",
        "    # Bidirectional LSTM layer for capturing temporal dependencies in the data\n",
        "    Bidirectional(LSTM(128, return_sequences=False), input_shape=(5447, 13)),\n",
        "    Dropout(0.5),  # Dropout layer for regularization to prevent overfitting\n",
        "    Dense(32, activation='relu'),  # Fully connected layer with ReLU activation\n",
        "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
        "])\n",
        "model_1.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])  # Compile the model with binary crossentropy loss and Adam optimizer\n",
        "model_1.summary()  # Display model summary"
      ],
      "metadata": {
        "id": "B8N51qHXZ4YD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2: Dense neural network for training and classification\n",
        "input_train = []  # Prepare input data for the model\n",
        "for i in range(460):\n",
        "    input_train.append(X_train[i].flatten())\n",
        "\n",
        "input_train.shape\n",
        "#(460, number)\n",
        "\n",
        "model_2 = Sequential([\n",
        "    Dense(100, input_shape=(number,), activation='relu'),  # Fully connected layer with ReLU activation\n",
        "    Dense(200, activation='relu'),  # Fully connected layer with ReLU activation\n",
        "    Dense(100, activation='relu'),  # Fully connected layer with ReLU activation\n",
        "    Dense(100, activation='relu'),  # Fully connected layer with ReLU activation\n",
        "    Dropout(0.2),  # Dropout layer for regularization to prevent overfitting\n",
        "    Dense(100, activation='relu'),  # Fully connected layer with ReLU activation\n",
        "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
        "])\n",
        "model_2.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Compile the model with binary crossentropy loss and Adam optimizer\n",
        "model_2.summary()  # Display model summary"
      ],
      "metadata": {
        "id": "5boKclNeZ_gF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 4: Convolutional neural network for training and classification\n",
        "model_3 = Sequential([\n",
        "    Conv2D(16, (3, 3), input_shape=(5447, 13, 1), activation='relu', padding='same'),  # Convolutional layer with ReLU activation\n",
        "    MaxPooling2D(pool_size=(2, 2)),  # Max pooling layer\n",
        "    Conv2D(32, (3, 3), activation='relu', padding='same'),  # Convolutional layer with ReLU activation\n",
        "    MaxPooling2D(pool_size=(2, 2)),  # Max pooling layer\n",
        "    Conv2D(64, (3, 3), activation='relu', padding='same'),  # Convolutional layer with ReLU activation\n",
        "    MaxPooling2D(pool_size=(2, 2)),  # Max pooling layer\n",
        "    GlobalAveragePooling2D(),  # Global average pooling layer\n",
        "    Dropout(0.5),  # Dropout layer for regularization to prevent overfitting\n",
        "    Dense(128, activation='relu'),  # Fully connected layer with ReLU activation\n",
        "    Dropout(0.3),  # Dropout layer for regularization to prevent overfitting\n",
        "    Dense(1, activation='sigmoid')  # Output layer with sigmoid activation for binary classification\n",
        "])\n",
        "model_3.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])  # Compile the model with binary crossentropy loss and Adam optimizer\n",
        "model_3.summary()  # Display model summary"
      ],
      "metadata": {
        "id": "1VxuM0bNaV2O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}